{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "\n",
    "dataset = pd.read_csv('alzheimers_prediction_dataset.csv')\n",
    "dataset = dataset.drop(columns = ['Country']) \n",
    "dataset['Gender'] = dataset['Gender'].map({'Male': 0, 'Female': 1})\n",
    "dataset['Physical Activity Level'] = dataset['Physical Activity Level'].map({'Low': 0, 'Medium': 1, 'High': 2})\n",
    "dataset['Smoking Status'] = dataset['Smoking Status'].map({'Never': 0, 'Former': 1, 'Current': 2})\n",
    "dataset['Alcohol Consumption'] = dataset['Alcohol Consumption'].map({'Never': 0, 'Occasionally': 1, 'Regularly': 2})\n",
    "dataset['Diabetes'] = dataset['Diabetes'].map({'No': 0, 'Yes': 1})\n",
    "dataset['Hypertension'] = dataset['Hypertension'].map({'No': 0, 'Yes': 1})\n",
    "dataset['Cholesterol Level'] = dataset['Cholesterol Level'].map({'Normal': 0, 'High': 1})\n",
    "dataset['Family History of Alzheimer’s'] = dataset['Family History of Alzheimer’s'].map({'No': 0, 'Yes': 1})\n",
    "dataset['Depression Level'] = dataset['Depression Level'].map({'Low': 0, 'Medium': 1, 'High': 2})\n",
    "dataset['Sleep Quality'] = dataset['Sleep Quality'].map({'Poor': 0, 'Average': 1, 'Good': 2})\n",
    "dataset['Dietary Habits'] = dataset['Dietary Habits'].map({'Unhealthy': 0, 'Average': 1, 'Healthy': 2})\n",
    "dataset['Air Pollution Exposure'] = dataset['Air Pollution Exposure'].map({'Low': 0, 'Medium': 1, 'High': 2})\n",
    "dataset['Employment Status'] = dataset['Employment Status'].map({'Retired': 0, 'Unemployed': 1, 'Employed': 2})\n",
    "dataset['Marital Status'] = dataset['Marital Status'].map({'Widowed': 0, 'Married': 1, 'Single': 2})\n",
    "dataset['Genetic Risk Factor (APOE-ε4 allele)'] = dataset['Genetic Risk Factor (APOE-ε4 allele)'].map({'No': 0, 'Yes': 1})\n",
    "dataset['Social Engagement Level'] = dataset['Social Engagement Level'].map({'Low': 0, 'Medium': 1, 'High': 2})\n",
    "dataset['Income Level'] = dataset['Income Level'].map({'Low': 0, 'Medium': 1, 'High': 2})\n",
    "dataset['Stress Levels'] = dataset['Stress Levels'].map({'Low': 0, 'Medium': 1, 'High': 2})\n",
    "dataset['Urban vs Rural Living'] = dataset['Urban vs Rural Living'].map({'Urban': 0, 'Rural': 1})\n",
    "dataset['Alzheimer’s Diagnosis'] = dataset['Alzheimer’s Diagnosis'].map({'No': 0, 'Yes': 1})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.drop(columns=['Alzheimer’s Diagnosis']) \n",
    "y = dataset['Alzheimer’s Diagnosis']  \n",
    "split_percentage = 0.8  \n",
    "rows = len(dataset)\n",
    "split_index = int(rows * split_percentage)\n",
    "X_train = X[:split_index]\n",
    "X_test = X[split_index:]\n",
    "y_train = y[:split_index]\n",
    "y_test = y[split_index:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m5943/5943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1ms/step - accuracy: 0.6558 - loss: 0.6329\n",
      "Epoch 2/50\n",
      "\u001b[1m5943/5943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1ms/step - accuracy: 0.6885 - loss: 0.5829\n",
      "Epoch 3/50\n",
      "\u001b[1m5943/5943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - accuracy: 0.7011 - loss: 0.5673\n",
      "Epoch 4/50\n",
      "\u001b[1m5943/5943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - accuracy: 0.7025 - loss: 0.5631\n",
      "Epoch 5/50\n",
      "\u001b[1m5943/5943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - accuracy: 0.7068 - loss: 0.5567\n",
      "Epoch 6/50\n",
      "\u001b[1m5943/5943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - accuracy: 0.7019 - loss: 0.5586\n",
      "Epoch 7/50\n",
      "\u001b[1m5943/5943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - accuracy: 0.7044 - loss: 0.5587\n",
      "Epoch 8/50\n",
      "\u001b[1m5943/5943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - accuracy: 0.7061 - loss: 0.5558\n",
      "Epoch 9/50\n",
      "\u001b[1m5943/5943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - accuracy: 0.7052 - loss: 0.5556\n",
      "Epoch 10/50\n",
      "\u001b[1m5943/5943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - accuracy: 0.7035 - loss: 0.5565\n",
      "Epoch 11/50\n",
      "\u001b[1m5943/5943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - accuracy: 0.7098 - loss: 0.5517\n",
      "Epoch 12/50\n",
      "\u001b[1m5943/5943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - accuracy: 0.7073 - loss: 0.5555\n",
      "Epoch 13/50\n",
      "\u001b[1m5943/5943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - accuracy: 0.7060 - loss: 0.5557\n",
      "Epoch 14/50\n",
      "\u001b[1m5943/5943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - accuracy: 0.7067 - loss: 0.5510\n",
      "Epoch 15/50\n",
      "\u001b[1m5943/5943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - accuracy: 0.7079 - loss: 0.5508\n",
      "Epoch 16/50\n",
      "\u001b[1m5943/5943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1ms/step - accuracy: 0.7097 - loss: 0.5515\n",
      "Epoch 17/50\n",
      "\u001b[1m5943/5943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - accuracy: 0.7093 - loss: 0.5493\n",
      "Epoch 18/50\n",
      "\u001b[1m5943/5943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - accuracy: 0.7095 - loss: 0.5497\n",
      "Epoch 19/50\n",
      "\u001b[1m5943/5943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - accuracy: 0.7109 - loss: 0.5479\n",
      "Epoch 20/50\n",
      "\u001b[1m5943/5943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - accuracy: 0.7098 - loss: 0.5483\n",
      "Epoch 21/50\n",
      "\u001b[1m5943/5943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - accuracy: 0.7121 - loss: 0.5481\n",
      "Epoch 22/50\n",
      "\u001b[1m5943/5943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - accuracy: 0.7156 - loss: 0.5448\n",
      "Epoch 23/50\n",
      "\u001b[1m5943/5943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - accuracy: 0.7139 - loss: 0.5481\n",
      "Epoch 24/50\n",
      "\u001b[1m5943/5943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - accuracy: 0.7155 - loss: 0.5470\n",
      "Epoch 25/50\n",
      "\u001b[1m5943/5943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - accuracy: 0.7166 - loss: 0.5436\n",
      "Epoch 26/50\n",
      "\u001b[1m5943/5943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1ms/step - accuracy: 0.7123 - loss: 0.5467\n",
      "Epoch 27/50\n",
      "\u001b[1m5943/5943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1ms/step - accuracy: 0.7107 - loss: 0.5473\n",
      "Epoch 28/50\n",
      "\u001b[1m5943/5943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - accuracy: 0.7101 - loss: 0.5480\n",
      "Epoch 29/50\n",
      "\u001b[1m5943/5943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1ms/step - accuracy: 0.7128 - loss: 0.5466\n",
      "Epoch 30/50\n",
      "\u001b[1m5943/5943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - accuracy: 0.7095 - loss: 0.5485\n",
      "Epoch 31/50\n",
      "\u001b[1m5943/5943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - accuracy: 0.7167 - loss: 0.5443\n",
      "Epoch 32/50\n",
      "\u001b[1m5943/5943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1ms/step - accuracy: 0.7157 - loss: 0.5442\n",
      "Epoch 33/50\n",
      "\u001b[1m5943/5943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - accuracy: 0.7162 - loss: 0.5450\n",
      "Epoch 34/50\n",
      "\u001b[1m5943/5943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - accuracy: 0.7177 - loss: 0.5436\n",
      "Epoch 35/50\n",
      "\u001b[1m5943/5943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1ms/step - accuracy: 0.7156 - loss: 0.5437\n",
      "Epoch 36/50\n",
      "\u001b[1m5943/5943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1ms/step - accuracy: 0.7136 - loss: 0.5458\n",
      "Epoch 37/50\n",
      "\u001b[1m5943/5943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1ms/step - accuracy: 0.7175 - loss: 0.5464\n",
      "Epoch 38/50\n",
      "\u001b[1m5943/5943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - accuracy: 0.7162 - loss: 0.5452\n",
      "Epoch 39/50\n",
      "\u001b[1m5943/5943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - accuracy: 0.7148 - loss: 0.5475\n",
      "Epoch 40/50\n",
      "\u001b[1m5943/5943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1ms/step - accuracy: 0.7127 - loss: 0.5468\n",
      "Epoch 41/50\n",
      "\u001b[1m5943/5943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - accuracy: 0.7152 - loss: 0.5452\n",
      "Epoch 42/50\n",
      "\u001b[1m5943/5943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - accuracy: 0.7155 - loss: 0.5436\n",
      "Epoch 43/50\n",
      "\u001b[1m5943/5943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1ms/step - accuracy: 0.7167 - loss: 0.5422\n",
      "Epoch 44/50\n",
      "\u001b[1m5943/5943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - accuracy: 0.7191 - loss: 0.5393\n",
      "Epoch 45/50\n",
      "\u001b[1m5943/5943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - accuracy: 0.7156 - loss: 0.5442\n",
      "Epoch 46/50\n",
      "\u001b[1m5943/5943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - accuracy: 0.7206 - loss: 0.5418\n",
      "Epoch 47/50\n",
      "\u001b[1m5943/5943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1ms/step - accuracy: 0.7134 - loss: 0.5464\n",
      "Epoch 48/50\n",
      "\u001b[1m5943/5943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - accuracy: 0.7202 - loss: 0.5391\n",
      "Epoch 49/50\n",
      "\u001b[1m5943/5943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - accuracy: 0.7143 - loss: 0.5453\n",
      "Epoch 50/50\n",
      "\u001b[1m5943/5943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1ms/step - accuracy: 0.7177 - loss: 0.5440\n",
      "\u001b[1m1858/1858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7172 - loss: 0.5395\n",
      "Accuracy: 71.81\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Input(shape=(23,)))\n",
    "model.add(Dense(128, activation= 'relu'))\n",
    "model.add(Dense(64, activation = 'relu'))\n",
    "model.add(Dense(32, activation = 'relu'))\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=10)  \n",
    "_, accuracy = model.evaluate(X_train, y_train)  \n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 802us/step\n",
      "0 = No, 1 = Yes\n",
      "Row 0 => 1 (expected 0)\n",
      "Row 1000 => 1 (expected 0)\n",
      "Row 2000 => 1 (expected 0)\n",
      "Row 3000 => 1 (expected 1)\n",
      "Row 4000 => 1 (expected 1)\n",
      "Row 5000 => 0 (expected 0)\n",
      "Row 6000 => 1 (expected 1)\n",
      "Row 7000 => 1 (expected 1)\n",
      "Row 8000 => 0 (expected 1)\n",
      "Row 9000 => 0 (expected 0)\n",
      "Row 10000 => 0 (expected 1)\n",
      "Row 11000 => 1 (expected 1)\n",
      "Row 12000 => 0 (expected 1)\n",
      "Row 13000 => 1 (expected 1)\n",
      "Row 14000 => 1 (expected 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Temp\\ipykernel_3696\\1168437969.py:5: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  print('Row %d => %d (expected %d)' % (i, predictions[i], y_test.iloc[i]))\n"
     ]
    }
   ],
   "source": [
    "predictions = (model.predict(X_test) > 0.5).astype(int)\n",
    "\n",
    "print(\"0 = No, 1 = Yes\")\n",
    "for i in range(0,len(X_test),1000):  \n",
    "    print('Row %d => %d (expected %d)' % (i, predictions[i], y_test.iloc[i]))  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
